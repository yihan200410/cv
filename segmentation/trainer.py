import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from pathlib import Path
import numpy as np
from typing import Optional, Tuple, Dict, Any


class DiceLoss(nn.Module):
    """Dice Loss - ä¸“æ³¨äºåˆ†å‰²åŒºåŸŸé‡å """

    def __init__(self, smooth: float = 1e-6):
        super().__init__()
        self.smooth = smooth

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­

        Args:
            inputs: é¢„æµ‹å€¼ (logits), shape [B, 1, H, W]
            targets: çœŸå®æ ‡ç­¾, shape [B, 1, H, W]

        Returns:
            Dice losså€¼
        """
        inputs = torch.sigmoid(inputs)

        # å±•å¹³å¼ é‡
        inputs_flat = inputs.view(-1)
        targets_flat = targets.view(-1)

        intersection = (inputs_flat * targets_flat).sum()
        dice_score = (2. * intersection + self.smooth) / (
                inputs_flat.sum() + targets_flat.sum() + self.smooth
        )

        return 1 - dice_score


class FocalLoss(nn.Module):
    """Focal Loss - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""

    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        inputs = torch.sigmoid(inputs)

        # è®¡ç®—äºŒå…ƒäº¤å‰ç†µ
        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')

        # Focal lossæƒé‡
        pt = inputs * targets + (1 - inputs) * (1 - targets)
        focal_weight = self.alpha * (1 - pt) ** self.gamma

        focal_loss = focal_weight * bce_loss
        return focal_loss.mean()


class FocalDiceLoss(nn.Module):
    """Focal + Dice ç»„åˆæŸå¤± - å¹³è¡¡éš¾æ˜“æ ·æœ¬å¹¶å…³æ³¨åŒºåŸŸé‡å """

    def __init__(self,
                 alpha: float = 0.25,
                 gamma: float = 2.0,
                 dice_weight: float = 0.7,
                 focal_weight: float = 0.3,
                 smooth: float = 1e-6):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.dice_weight = dice_weight
        self.focal_weight = focal_weight
        self.smooth = smooth

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        # Dice Loss
        inputs_sigmoid = torch.sigmoid(inputs)
        intersection = (inputs_sigmoid * targets).sum(dim=(1, 2, 3))
        union = inputs_sigmoid.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3))
        dice_score = (2.0 * intersection + self.smooth) / (union + self.smooth)
        dice_loss = 1.0 - dice_score.mean()

        # Focal Loss
        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')
        pt = torch.exp(-bce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss
        focal_loss = focal_loss.mean()

        # ç»„åˆæŸå¤±
        total_loss = self.dice_weight * dice_loss + self.focal_weight * focal_loss

        return total_loss


class TverskyLoss(nn.Module):
    """Tversky Loss - æ§åˆ¶ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„å¹³è¡¡"""

    def __init__(self, alpha: float = 0.7, beta: float = 0.3, smooth: float = 1e-6):
        """
        Args:
            alpha: å‡é˜³æ€§çš„æƒé‡ (æ§åˆ¶ç²¾ç¡®ç‡)
            beta: å‡é˜´æ€§çš„æƒé‡ (æ§åˆ¶å¬å›ç‡)
            alpha=0.7, beta=0.3 æ›´æ³¨é‡å¬å›ç‡
        """
        super().__init__()
        self.alpha = alpha
        self.beta = beta
        self.smooth = smooth

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        inputs = torch.sigmoid(inputs)

        # True Positives, False Positives, False Negatives
        tp = (inputs * targets).sum(dim=(1, 2, 3))
        fp = (inputs * (1 - targets)).sum(dim=(1, 2, 3))
        fn = ((1 - inputs) * targets).sum(dim=(1, 2, 3))

        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)
        tversky_loss = 1 - tversky.mean()

        return tversky_loss


class IoULoss(nn.Module):
    """IoU Loss - ç›´æ¥ä¼˜åŒ–IoUæŒ‡æ ‡"""

    def __init__(self, smooth: float = 1e-6):
        super().__init__()
        self.smooth = smooth

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        inputs = torch.sigmoid(inputs)

        intersection = (inputs * targets).sum(dim=(1, 2, 3))
        union = inputs.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) - intersection

        iou = (intersection + self.smooth) / (union + self.smooth)
        iou_loss = 1 - iou.mean()

        return iou_loss


class ComboLoss(nn.Module):
    """ç»„åˆæŸå¤±ï¼šDice + BCE + L2æ­£åˆ™åŒ–"""

    def __init__(self,
                 dice_weight: float = 0.7,
                 bce_weight: float = 0.3,
                 l2_weight: float = 0.01,
                 smooth: float = 1e-6):
        super().__init__()
        self.dice_weight = dice_weight
        self.bce_weight = bce_weight
        self.l2_weight = l2_weight
        self.smooth = smooth

    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        # Dice Loss
        inputs_sigmoid = torch.sigmoid(inputs)
        intersection = (inputs_sigmoid * targets).sum(dim=(1, 2, 3))
        union = inputs_sigmoid.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3))
        dice_score = (2.0 * intersection + self.smooth) / (union + self.smooth)
        dice_loss = 1.0 - dice_score.mean()

        # BCE Loss
        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets)

        # L2æ­£åˆ™åŒ–ï¼ˆé€šè¿‡æƒé‡è¡°å‡å®ç°ï¼Œè¿™é‡Œä»…ä¸ºå±•ç¤ºï¼‰
        total_loss = (self.dice_weight * dice_loss +
                      self.bce_weight * bce_loss)

        return total_loss


class IoUScore:
    """IoUï¼ˆäº¤å¹¶æ¯”ï¼‰è®¡ç®—å™¨"""

    def __init__(self, threshold: float = 0.5, smooth: float = 1e-6):
        self.threshold = threshold
        self.smooth = smooth

    def __call__(self, inputs: torch.Tensor, targets: torch.Tensor) -> float:
        """è®¡ç®—IoU

        Args:
            inputs: é¢„æµ‹å€¼ (logits), shape [B, 1, H, W]
            targets: çœŸå®æ ‡ç­¾, shape [B, 1, H, W]

        Returns:
            IoUå€¼
        """
        # å¦‚æœè¾“å…¥æ˜¯logitsï¼Œå…ˆè¿›è¡Œsigmoid
        if inputs.max() > 1 or inputs.min() < 0:
            inputs = torch.sigmoid(inputs)

        preds = (inputs > self.threshold).float()
        targets = (targets > 0.5).float()

        intersection = (preds * targets).sum(dim=(1, 2, 3))
        union = preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) - intersection

        iou = (intersection + self.smooth) / (union + self.smooth)

        return iou.mean().item()


class DiceScore:
    """Diceç³»æ•°è®¡ç®—å™¨"""

    def __init__(self, threshold: float = 0.5, smooth: float = 1e-6):
        self.threshold = threshold
        self.smooth = smooth

    def __call__(self, inputs: torch.Tensor, targets: torch.Tensor) -> float:
        if inputs.max() > 1 or inputs.min() < 0:
            inputs = torch.sigmoid(inputs)

        preds = (inputs > self.threshold).float()
        targets = (targets > 0.5).float()

        intersection = (preds * targets).sum(dim=(1, 2, 3))
        dice = (2. * intersection + self.smooth) / (
                preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) + self.smooth
        )

        return dice.mean().item()


class Trainer:
    """U-Netè®­ç»ƒå™¨ - æ”¯æŒå¤šç§æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥"""

    def __init__(self,
                 model: nn.Module,
                 train_loader,
                 val_loader,
                 device: str = 'cuda',
                 loss_type: str = 'focal_dice',
                 learning_rate: float = 1e-4,
                 weight_decay: float = 1e-4,
                 patience: int = 15):
        """
        Args:
            model: U-Netæ¨¡å‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            device: è®­ç»ƒè®¾å¤‡
            loss_type: æŸå¤±å‡½æ•°ç±»å‹
            learning_rate: å­¦ä¹ ç‡
            weight_decay: æƒé‡è¡°å‡
            patience: æ—©åœè€å¿ƒå€¼
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device

        # é€‰æ‹©æŸå¤±å‡½æ•°
        self.loss_type = loss_type
        self.criterion = self._get_loss_function(loss_type)

        # ä¼˜åŒ–å™¨é…ç½®
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=10,
            T_mult=2,
            eta_min=1e-6,
            last_epoch=-1
        )

        # æŒ‡æ ‡è®¡ç®—å™¨
        self.iou_calculator = IoUScore()
        self.dice_calculator = DiceScore()

        # è®­ç»ƒçŠ¶æ€
        self.best_val_iou = 0.0
        self.best_val_dice = 0.0
        self.patience_counter = 0
        self.patience = patience
        self.epoch_history = {
            'train_loss': [],
            'train_iou': [],
            'val_loss': [],
            'val_iou': [],
            'val_dice': [],
            'learning_rate': []
        }

        # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.checkpoint_dir = Path(f"checkpoints/unet_{loss_type}_{timestamp}")
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

        # TensorBoardæ—¥å¿—ç›®å½•
        self.log_dir = Path(f"logs/tensorboard_{loss_type}_{timestamp}")
        self.writer = SummaryWriter(str(self.log_dir))

        # æ‰“å°é…ç½®ä¿¡æ¯
        self._print_config(learning_rate, weight_decay)

    def _get_loss_function(self, loss_type: str) -> nn.Module:
        """è·å–æŸå¤±å‡½æ•°"""
        loss_functions = {
            'bce': nn.BCEWithLogitsLoss(),
            'dice': DiceLoss(),
            'focal': FocalLoss(),
            'focal_dice': FocalDiceLoss(dice_weight=0.7, focal_weight=0.3),
            'tversky': TverskyLoss(alpha=0.7, beta=0.3),
            'iou': IoULoss(),
            'combo': ComboLoss(),
        }

        if loss_type not in loss_functions:
            raise ValueError(f"ä¸æ”¯æŒçš„æŸå¤±å‡½æ•°ç±»å‹: {loss_type}")

        print(f"ä½¿ç”¨ {loss_type} æŸå¤±å‡½æ•°")
        return loss_functions[loss_type]

    def _print_config(self, lr: float, wd: float):
        """æ‰“å°è®­ç»ƒé…ç½®"""
        print("\n" + "=" * 50)
        print("è®­ç»ƒé…ç½®")
        print("=" * 50)
        print(f"æ¨¡å‹æ¶æ„: {self.model.__class__.__name__}")
        print(f"è®¾å¤‡: {self.device}")
        print(f"æŸå¤±å‡½æ•°: {self.loss_type}")
        print(f"å­¦ä¹ ç‡: {lr}")
        print(f"æƒé‡è¡°å‡: {wd}")
        print(f"æ—©åœè€å¿ƒå€¼: {self.patience}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(self.val_loader.dataset)}")
        print(f"æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„: {self.checkpoint_dir}")
        print(f"TensorBoardæ—¥å¿—è·¯å¾„: {self.log_dir}")
        print("=" * 50 + "\n")

    def train_epoch(self, epoch: int) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_loss = 0.0
        epoch_iou = 0.0
        num_batches = 0

        pbar = tqdm(self.train_loader, desc=f'è®­ç»ƒ Epoch {epoch + 1}',
                    leave=False, position=0)

        for batch_idx, (images, masks) in enumerate(pbar):
            images = images.to(self.device)
            masks = masks.to(self.device)

            # å‰å‘ä¼ æ’­
            outputs = self.model(images)
            loss = self.criterion(outputs, masks)

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            self.optimizer.zero_grad()
            loss.backward()

            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(),
                max_norm=1.0
            )

            self.optimizer.step()

            # è®¡ç®—æŒ‡æ ‡
            with torch.no_grad():
                iou = self.iou_calculator(outputs, masks)
                dice = self.dice_calculator(outputs, masks)

            epoch_loss += loss.item()
            epoch_iou += iou
            num_batches += 1

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'IoU': f'{iou:.4f}',
                'Dice': f'{dice:.4f}',
                'LR': f'{self.optimizer.param_groups[0]["lr"]:.6f}'
            })

            # TensorBoardè®°å½•ï¼ˆæ¯100ä¸ªbatchè®°å½•ä¸€æ¬¡ï¼‰
            if batch_idx % 100 == 0:
                global_step = epoch * len(self.train_loader) + batch_idx
                self.writer.add_scalar('Train/Batch_Loss', loss.item(), global_step)
                self.writer.add_scalar('Train/Batch_IoU', iou, global_step)
                self.writer.add_scalar('Train/Batch_Dice', dice, global_step)

        return epoch_loss / num_batches, epoch_iou / num_batches

    def validate(self) -> Tuple[float, float, float]:
        """éªŒè¯"""
        self.model.eval()
        val_loss = 0.0
        val_iou = 0.0
        val_dice = 0.0
        num_batches = 0

        with torch.no_grad():
            val_pbar = tqdm(self.val_loader, desc='éªŒè¯',
                            leave=False, position=0)

            for images, masks in val_pbar:
                images = images.to(self.device)
                masks = masks.to(self.device)

                outputs = self.model(images)
                loss = self.criterion(outputs, masks)
                iou = self.iou_calculator(outputs, masks)
                dice = self.dice_calculator(outputs, masks)

                val_loss += loss.item()
                val_iou += iou
                val_dice += dice
                num_batches += 1

                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'IoU': f'{iou:.4f}',
                    'Dice': f'{dice:.4f}'
                })

        return (val_loss / num_batches,
                val_iou / num_batches,
                val_dice / num_batches)

    def save_checkpoint(self,
                        epoch: int,
                        val_iou: float,
                        val_dice: float,
                        is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'val_iou': val_iou,
            'val_dice': val_dice,
            'loss_type': self.loss_type,
            'epoch_history': self.epoch_history,
            'best_val_iou': self.best_val_iou,
            'best_val_dice': self.best_val_dice,
        }

        if is_best:
            torch.save(checkpoint, self.checkpoint_dir / 'best_model.pth')
        else:
            torch.save(checkpoint, self.checkpoint_dir / f'checkpoint_epoch_{epoch + 1}.pth')

    def train(self, epochs: int = 50) -> Dict[str, Any]:
        """å®Œæ•´è®­ç»ƒè¿‡ç¨‹

        Args:
            epochs: è®­ç»ƒè½®æ•°

        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        print(f"å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} è½®...")

        for epoch in range(epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss, train_iou = self.train_epoch(epoch)

            # éªŒè¯
            val_loss, val_iou, val_dice = self.validate()

            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step(val_iou)
            current_lr = self.optimizer.param_groups[0]['lr']

            # ä¿å­˜å†å²è®°å½•
            self.epoch_history['train_loss'].append(train_loss)
            self.epoch_history['train_iou'].append(train_iou)
            self.epoch_history['val_loss'].append(val_loss)
            self.epoch_history['val_iou'].append(val_iou)
            self.epoch_history['val_dice'].append(val_dice)
            self.epoch_history['learning_rate'].append(current_lr)

            # æ‰“å°epochç»“æœ
            print(f"\nEpoch {epoch + 1}/{epochs}:")
            print(f"  è®­ç»ƒ - Loss: {train_loss:.4f}, IoU: {train_iou:.4f}")
            print(f"  éªŒè¯ - Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, Dice: {val_dice:.4f}")
            print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")

            # TensorBoardè®°å½•
            self.writer.add_scalar('Loss/Train', train_loss, epoch)
            self.writer.add_scalar('Loss/Val', val_loss, epoch)
            self.writer.add_scalar('IoU/Train', train_iou, epoch)
            self.writer.add_scalar('IoU/Val', val_iou, epoch)
            self.writer.add_scalar('Dice/Val', val_dice, epoch)
            self.writer.add_scalar('Learning_Rate', current_lr, epoch)

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_iou > self.best_val_iou:
                self.best_val_iou = val_iou
                self.best_val_dice = val_dice
                self.patience_counter = 0

                self.save_checkpoint(epoch, val_iou, val_dice, is_best=True)
                print(f"  âœ… æœ€ä½³æ¨¡å‹ä¿å­˜ï¼ŒIoU: {val_iou:.4f}, Dice: {val_dice:.4f}")
            else:
                self.patience_counter += 1
                print(f"  â³ æ— æ”¹å–„ ({self.patience_counter}/{self.patience})")

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % 10 == 0:
                self.save_checkpoint(epoch, val_iou, val_dice, is_best=False)
                print(f"  ğŸ’¾ æ£€æŸ¥ç‚¹ä¿å­˜")

            # æ—©åœæ£€æŸ¥
            if self.patience_counter >= self.patience:
                print(f"\nâš ï¸  æ—©åœè§¦å‘ï¼{self.patience}ä¸ªepochæ— æ”¹å–„")
                break

        # è®­ç»ƒå®Œæˆ
        self.writer.close()

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_checkpoint = {
            'epoch': epochs,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'val_iou': val_iou,
            'val_dice': val_dice,
            'loss_type': self.loss_type,
            'epoch_history': self.epoch_history,
            'best_val_iou': self.best_val_iou,
            'best_val_dice': self.best_val_dice,
        }
        torch.save(final_checkpoint, self.checkpoint_dir / 'final_model.pth')

        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 50)
        print("è®­ç»ƒå®Œæˆ!")
        print("=" * 50)
        print(f"æœ€ä½³éªŒè¯IoU: {self.best_val_iou:.4f}")
        print(f"æœ€ä½³éªŒè¯Dice: {self.best_val_dice:.4f}")
        print(f"æœ€ç»ˆéªŒè¯IoU: {val_iou:.4f}")
        print(f"æœ€ç»ˆéªŒè¯Dice: {val_dice:.4f}")
        print(f"æ€»è®­ç»ƒè½®æ•°: {epoch + 1}")
        print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {self.checkpoint_dir}")
        print("=" * 50)

        return {
            'best_iou': self.best_val_iou,
            'best_dice': self.best_val_dice,
            'final_iou': val_iou,
            'final_dice': val_dice,
            'epoch_history': self.epoch_history,
            'checkpoint_dir': str(self.checkpoint_dir)
        }

    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        self.best_val_iou = checkpoint['best_val_iou']
        self.best_val_dice = checkpoint['best_val_dice']
        self.epoch_history = checkpoint['epoch_history']

        print(f"åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        print(f"Epoch: {checkpoint['epoch']}")
        print(f"éªŒè¯IoU: {checkpoint['val_iou']:.4f}")
        print(f"éªŒè¯Dice: {checkpoint['val_dice']:.4f}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from datetime import datetime
    from torch.utils.data import DataLoader
    import torchvision.transforms as transforms

    # ç¤ºä¾‹ç”¨æ³•
    print("ç¤ºä¾‹ç”¨æ³•:")
    print("1. å‡†å¤‡æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨")
    print("2. åˆå§‹åŒ–U-Netæ¨¡å‹")
    print("3. åˆ›å»ºTrainerå®ä¾‹")
    print("4. å¼€å§‹è®­ç»ƒ")

    # ä¼ªä»£ç ç¤ºä¾‹
    """
    # å‡è®¾ä½ å·²ç»æœ‰äº†è¿™äº›ç»„ä»¶
    train_loader = DataLoader(...)
    val_loader = DataLoader(...)
    model = UNet(in_channels=3, out_channels=1)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device='cuda' if torch.cuda.is_available() else 'cpu',
        loss_type='focal_dice',  # å¯ä»¥é€‰æ‹©: 'bce', 'dice', 'focal', 'focal_dice', 'tversky', 'iou', 'combo'
        learning_rate=1e-4,
        weight_decay=1e-4,
        patience=15
    )

    # å¼€å§‹è®­ç»ƒ
    results = trainer.train(epochs=50)

    # æˆ–è€…åŠ è½½æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ
    # trainer.load_checkpoint('checkpoints/unet_focal_dice/best_model.pth')
    # results = trainer.train(epochs=30)
    """